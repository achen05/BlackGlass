<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title></title>
  </head>
  <body>
    <div class="website-container">
      <h1>IT'S THE <br>BLACK GLASS<br>NOT THE <br>BLACK MIRROR</h1>
      <h2>Facing the aesthetics of the GUI and the paradox of transparent computation.</h2>
      <div class="authorship">
        <p>ALDON CHEN</p>
        <p>DECEMBER 2021</p>
      </div>
      <div id="glass-box"></div>
      <p class="caption">The 'glass' material block from the iconic sandbox simulation video game, Minecraft. Simulation by the auther using the P5.js library.</p>

    <div class="copy-container">
      <p class="copy">
        In The Ecstasy of Communication, French sociologist Jean Baudrillard uses the examples of the television and radio to argue that during an age of mass communication technology when information is exchanged overwhelmingly with little to no friction, we live in the ecstasy of everything being immediately transparent and exposed. Furthermore, Baudrillard argues that this ecstasy in obscene because in such a state of communication we are increasingly forming our understanding of reality within the confines of an ever-expanding network of interpretations of reality that come from others, and therefore are lessening our abilities to operate as individual interpreters of reality apart from such. Baudrillard’s warnings are more than relevant today in cultural criticisms which makes it tempting to apply Baudrillard’s argument to computers (and indeed it has been in various scholarly and popular debates) as the way the vast majority of the public interacts with computers is with the attitude that they are transparent glass windows that allow them to directly see the information displayed by acting as a direct representation of such. However, to argue with such an assumption would be dangerously inaccurate as computers do not merely represent the content that they display, and such an argument would distract from the possibility that computers themselves could potentially act as artificial interpreters of reality. Unlike the communication devices Baudrillad uses as examples in his essay, computers compute; they process and generate (or regenerate) information rather than simply relaying it. This essay addresses three issues regarding this attitude that computers are transparent communication devices: firstly the history of how this transparency culture towards computers was developed; secondly, why it is important to deconstruct this notion today, and finally, the reason why this issue is not merely an intellectual challenge but an aesthetic one as well.
<br>	Prior to the the icon-filled digital desktops the average computer user sees on their laptop today, monochromatic green and black text-based interfaces were the only way of navigating and interacting with early personal computers in the late 20th century. It wasn;’t until 1979 when the Xerox Palo Alto Research Center developed the first prototype for what is now known as a graphical user interface (GUI) would the industry see a new way of interacting with computers. Xerox’s Alto, a computer prototype consisting of a GUI and the traditional computer mouse, would spark Steve Jobs to bring the GUI to the public. Apple engineers would develop Lisa, the first publicly available GUI-based computer which, despite being a commercial failure, would eventually evolve into the exponentially more successful Macintosh in 1984. The GUI made the Macintosh incredibly easy to use, gaining widespread popularity from both users and developers who saw its potential for reaching the masses from its ease of use. One of the largest developers for Macintosh, Microsoft, would later replicate the concept of the GUI for Windows and the popularity of the two would eventually position the GUI as the standard for the vast majority of desktop computers. Today, the GUI has reached levels of popularity that the majority, if not all, of computer users no longer even think about the desktop metaphor any longer, which has simultaneously fostered the idea that computers are transparent in that they represent information directly and paradoxically became more opaque because the ever-complex methods of computation that a computer must perform while operating is now hidden away behind the easy to use GUI.
	<br>In an age when a significant bulk of the global population is active on some sort of algorthimically driven internet platform, it is increasisngly more important that users are aware that the content they are begin fed isnt representative of reality and are driven by alogrhtimally driven recommendation systems that amplify the content that they are witnessing. In a 2018 study published in RecSys '18: Proceedings of the 12th ACM Conference on Recommender Systems, authors from the Princeton University’s Department of Computer Science and Department of Sociology researched the ways in which feedback loops were created in online recommendatio systems used in internet platforms. The researches simulated recommendation systems using six different algorithms, each assuming 100 users over 1000 time intervals with 10 new items each interval. The results of comparing these simulations indicated three essential consequences of such a phenomenon. For the purposes of this essay, it is only necessary to summarize one of these consequences: the ways in which feedback loops cause the homogenization of user behavior by impacting the items they interact with on such online platforms. In particular, the study found that a social algorithm which homogenized users based on their connected users or cliques led to an echo chamber effect where the scope of content being fed to the user became narrower with each cycle of the simulation.
	<br>It isn’t too difficult to see how the conclusions of this study are reflective of the consequences of internet platforms today  and how the algorithms that power the recommendation systems on such platform work. Social media platforms today are designed to keep users engaged on their platform in order to maximize advertisement exposure and because of this, the content algorithms powering these platforms are designed to maximize the visibility of news that provoke strong emotions and draw attention. When algorithms pick up on something with strong engagement, it will promote that content to users it thinks will also have strong engagement with based on matching user profiles, resulting in the amplification of reactions towards the content even if it lacks context or is misleading. Cancel culture (also known as call-out culture) for instance, a contemporary form of ostracism that came into popular use through Twitter, arguably exploits the internet platform’s content recommendation system in order to sensationalize instances in which public figures, companies, brands, etc. have behaved inappropriately, immorally, etc. through the amplification of user outrage. From the resurfaced homophobic tweets of comedian  Kevin Hart, the backlash of whcih caused the comedian to step down from his role as host of the 2019 Oscars to [insert another example of cancel culture]...
The way information is represented on internet platforms deceives users into thinking that they are accurate, direct representations of reality when what the user is truly seeing is the careful curation of an algorithm designed to maximize their engagement through an echo chamber that inaccurately amplifies the scale and emotional significance of the content it serves.
	<br>This consequences of this issue do not seem to dwindle with increased awareness of algorithms either. A 2018 study published collected data on algorthk awareness in the Norwegian population with a representative sample of 1624 participants, parsing the results into various demographics and measured on a scale from ‘No awareness’ to ‘very high awareness.’The study found that “‘No awareness’ of algorithms is highest among the older respondents, while the two highest level of awareness is found among the youngest age groups.” If the assumption that intellectual awareness of algorithms were enough to alter how people interpreted the information they received, then behavior supposedly driven by a lack of awareness would symbiotically decrease. Yet a poll regarding cancel culture by Politico found that “Cancel culture is driven by younger voters. A majority (55%) of voters 18-34 say they have taken part in cancel culture, while only about a third (32%) of voters over 65 say they have joined a social media pile-on.” The fact that the demographics which had the most awareness of algorithms in content feeds were also the same demographic that were most likely to participate in cancel culture indicates that intellectual awareness of algorithms is not enough to change how people interpreted their information. It continues to be sensationalized and the reactions continue to be amplified.
<br>While Baudrillard’s warnings of mass communication technologies are still culturally accurate, for The Ecstasy of Communication to be relevant to computers in particular, it must go beyond the framing of centrally broadcasted information by considering the computer not as a direct medium of communication but as its own interpreter and organizer of information. People are increasingly becoming more aware of the ways computation affects the information they receive and yet the ever-increasing instances of internet cancel culture continue to demonstrate that the paradoxical culture of transparency towards computers persists. The continuation of this attitude in addition to the role of the GUI in its formation indicates that the challenge in deconstructing such an attitude requires not only an even wider intellectual understanding of the issue, but an aesthetic solution that reveals the opaqueness of computation as well.

      </p>

    </div>
    <script src="p5.js" charset="utf-8"></script>
    <script src="sketch.js" charset="utf-8"></script>
  </body>
</html>
